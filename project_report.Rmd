---
title: "Project"
author: "Marine Courtin"
date: "18 dÃ©cembre 2017"
output: html_document
---

```{r echo=FALSE}
`%>%` <- magrittr::`%>%`
```

```{r load_func}
source("functions.R")
```


# How verbs behave in Nigerian Pidgin and English

# 1. Introduction

In the project proposal, I described this data analysis problem as the comparison of the behaviour of verbs in Nigerian Pidgin and English. Initially I wanted to look at both the span of dependencies, and the types of the dependencies involving verbs. However doing this analysis, I realized that lookign at this problem using only spans would probably give more interesting results, as I have more data on them. Indeed, if we look at at the types of dependencies there is necessarily a lot more dispersion since there are around 30 types of dependencies (and even more if you take into account non-universal subtypes of syntactic relations). I also did not use the ngrams of part-of-speech that I had collected, as their addition probably would have distracted from the points I wanted to make on the spans. However these informations are still present in the tables I extracted from the treebanks, and could be used for future observations.

To summarize, I'm going to look at the spans for both verbs which are governor and verbs which are dependents, in both languages. A positive span indicates that a token is on the right of the reference verb it is linked to (exemple in _I ate an apple_, ate->apple has a positive span), while a negative span indicates that the token is on the left (in the same sentence I<-ate has a negative span. The absolute value of the span represents the distance between the reference verb and the other token, for example if the span is equal to one, then the token immediately follows the reference verb.

## 1.1 Cleaning the data

One quick note I want to mention is that I modified the treebanks so that punctuations were not included in the dependency trees. The reasoning behind this choice relates to the use of the punctuation marks in the Naija treebank to mark information relative to macro-syntax and prosody (as it is based on oral speech and part of the project's objective is to study the syntax-prosody interface), while in the English treebank, they encode typical punctuation marks. So taking into account these tokens  would have exagerated differences which had nothing to do with syntax but rather with the encoding of informations of a different nature.

The treebanks of universal dependency (UD) use a set of "universal" (i.e shared by all treebanks) syntactic relation labels. In addition, developpers of treebanks may add a subtype to this relation, to encode information which might not be covered by the universal set but that they deem important (for example compound is a universal relation, to which you can add the subtype :svc to encode serial verb constructions, which gives you the relation compound:svc). Since these subtypes were not shared by both treebanks I stripped them from the relation types, leaving me with only the "universal", comparable relations.


## 1.2 Brief overview

```{r import_data}
gov <- rbind(read.table("../../projet/R_input/verbs_that_are_gov_naija.csv", 
                 header = TRUE), read.table("../../projet/R_input/verbs_that_are_gov_english.csv", 
                 header = TRUE))
dep <- rbind(read.table("../../projet/R_input/verbs_that_are_dep_naija.csv", 
                 header = TRUE), read.table("../../projet/R_input/verbs_that_are_dep_english.csv", 
                 header = TRUE))

gov_en <- gov %>% dplyr::filter(language=="english")
gov_pcm <- gov %>% dplyr::filter(language=="naija")

dep_en <- dep %>% dplyr::filter(language=="english")
dep_pcm <- dep %>% dplyr::filter(language=="naija")
```

First let's say we want to have a brief look at our data, to get an overview of the syntactic combinations of verbs in English and in Nigerian Pidgin.

```{r english}
# verbe : governor; span_dep
summary(gov_en[,setdiff(names(gov_en),c("token_id"))])

# verb : dependent; span_gov
summary(dep_en[,setdiff(names(dep_en),c("token_id"))])
```
```{r naija}
summary(gov_pcm[,setdiff(names(gov_pcm),c("token_id"))])

summary(dep_pcm[,setdiff(names(dep_pcm),c("token_id"))])
```

From these tables we can gather that :

+ we have a lot more data on English than on Nigerian Pidgin (which might cause some trouble for us later on)
+ for both languages, there are more instances of a verb having its dependent on its left side (see the median), however in English the mean span is positive. This observation, in combination with our remark on the median would indicate that in English governor-dependent relations which are directed on the right have greaters span than those directed towards the left.
+ verbs have a lot of nominal and pronominal dependents.
+ governors of verbs are often either verbs themselves or nouns
+ verbs often have their governor on their left in both languages.


## 1.3 Plan for the data analysis

As I mentionned previously, we will be focussing on the spans of dependencies involving verbs.For this purpose, we will distinguish two types of spans :

+ span_dep : span of a dependency between a verb and its dependent (i.e the verb is the governor)
+ span_gov : span of a dependency between a governor and its verb-dependent (i.e the verb if the dependent)

For each type of span, we want to look at the divergence in their distribution depending on the language. That is to say, we want to see if the distribution are "similar" (whatever that means) or if they are different enough that we could make an hypothesis on the language of the treebank based on the distribution of its spans' values. If the latter is true, that mean we might for example be able to reconstitute the language of a delexicalized treebank. 

When we look at the distribution of both groups for the variable span_dep, the unbalanced number of observations in each group make it difficult to see if there is an actual difference between the two groups. To remediate this problem, we will draw a subset of the "english" group to match the number of observations in the "naija" group and plot both distributions on the same histogram. Here's the result we get :

```{r span_dep}
ggplot2::ggplot(gov, ggplot2::aes(x=`span`, fill=language)) +
  ggplot2::geom_histogram(ggplot2::aes(y=..count..),alpha=0.5, bins=30, colour="black", position="identity") +
  ggplot2::xlim(c(-15, 15))

set.seed(1)
subset_gov <- gov %>% dplyr::filter(language=="english") %>% .[sample(1:nrow(.), nrow(dplyr::filter(gov, language=="naija")),replace=FALSE),] %>% rbind(., gov_pcm)

ggplot2::ggplot(subset_gov, ggplot2::aes(x=`span`, fill=language)) +
  ggplot2::geom_histogram(ggplot2::aes(y=..count..),alpha=0.5, bins=30, colour="black", position="identity") +
  ggplot2::xlim(c(-15, 15))
```



We now apply the same method to plot the distribution of values for the variable span_gov :
```{r span_gov}
ggplot2::ggplot(dep, ggplot2::aes(x=`span`, fill=language)) +
  ggplot2::geom_histogram(ggplot2::aes(y=..count..),alpha=0.5, bins=30, colour="black", position="identity") +
  ggplot2::xlim(c(-15, 15))

set.seed(1)
subset_dep <- dep %>% dplyr::filter(language=="english") %>% .[sample(1:nrow(.), nrow(dplyr::filter(dep, language=="naija")),replace=FALSE),] %>% rbind(., dep_pcm)

ggplot2::ggplot(subset_dep, ggplot2::aes(x=`span`, fill=language)) +
  ggplot2::geom_histogram(ggplot2::aes(y=..count..),alpha=0.5, bins=30, colour="black", position="identity") +
  ggplot2::xlim(c(-15, 15))

```

When looking at the histograms with a comparable number of observations for both groups, the distributions of the two languages seem pretty similar for both the span_dep and span_gov variables. We want to check whether the distributions are really similar or if they just look like they are. In order to do this we will procede as follows selecting first span_dep as our discrete random variable:

+ we define our sample space (the set of the possible values for the random variable) as the interval between the biggest positive and negative values for span_dep.
+ we then compute the probability that span_dep is equal to some value based on the English data, for every value in our sample space.
+ we then repeat this step for the Naija data.
+ we measure the divergence in the probability distributions between the two -> this will give us the relative entropy[^1] of the probability distribution of spans in the data on Naija with respect to the probability distribution of the spans in the English data. 
+ we create fake data in which the two groups share the same source of variability in relation to span_dep. For each iteration, we compute the relative entropy measure (our test statistics).
+ we plot the results with the fake data and compare with the observed result obtained with the real data. If this shows that the observed result would be unlikely with made up data, then we conclude that looking at the relative entropy of span_dep is pertinent.

Since one of our goals is to explore different features and metrics (or measures of distance) which might allow us to separate both groups we will then repeat these steps with the span_gov variable, to see if one of the two feature (span_dep and span_gov) is a better predictor.

This was the initial plan for our analysis. Unfortunately if we follow up with it, we will soon realize that there is a problem with the measure od distance we have selected. We will find that some values of span_dep and span_gov have a probability of 0 for one of the groups (since these spans aren't necessarily attested for both groups). We could of course take these values out of our sample space, but it would seem a bit unfair. What if having this type of span was very characteristic of one of our languages ? Instead, we will substitute this measure of distance for another which allows for zeroes : the Wasserstein metric.

I first tried writing my own functions (see `proba_spans` in the function file) before realizing there was a package which implemented the wasserstein metric when given two vectors as input. The function I used is `transport::wasserstein1d`. When I asked you about this metric, you said that I should probably check that its output was correct when compared to the examples on [the wikipedia page](https://en.wikipedia.org/wiki/Wasserstein_metric#Examples) but the descriptions used too many technical terms for me to get an understanding of how I would implement this verification, so I did not check that the output was correct, which isn't ideal..

```{r distance_distrib_proba_span, cache=TRUE}
wasserstein_gov_obs <- transport::wasserstein1d(gov_en[["span"]], gov_pcm[["span"]])

```

I then went on to build some fake data, with permuted languages, so as to compare the result of this test statistic when the two groups are identical in relation to our variable (fake data) and when they might not be (original data). This is called permutation and allows us to see what our distributions would look like in tha case of a null hypothesis (i.e when the groups are identical in relation to a source of variability). In our analysis, we know that both groups are different (as they are based on treebanks of different languages, whose syntax is different). However what we do not know is whether they are significatively different in relation to the spans of dependency, and if so which of the feature span_dep and span_gov allows us to best separate both groups.

Here are the results in the case of a null hypothesis (for span_dep):

```{r, cache=TRUE}

wasserstein_gov_fake <- wasserstein_table(2000, gov, "english", "naija", "span")
print(plot_permuted_wasserstein(wasserstein_gov_fake, wasserstein_gov_obs))
```

So we now have results from our fake data, which allows us to see what the Wasserstein metric looks like when the data comes from identical group (the distance is then < 0.3). If this feature is a good feature to separate both groups, we ought to get a higher value for our Wasserstein metric (which we did) and the higher this value is the most pertinent this feature is in distinguishing both groups.


The next step consists in generating more samples from our original data, to see what other values of our metric could have been obtained from a similar distribution as the distribution we observed. Our original data showed one specific distribution, which gives a specific result when comparing Wasserstein distances. However, we could have had another similar distribution (i.e with the same underlying distribution but with somare variations) which would have given a different result. This technique called boostrapping aims at giving us an idea of the type of result we could have reasonably obtained with the same underlying distribution. We then plot the results, adding indicators for the 1st quantile, 2rd quantile and median (the red lines). The black line serves as a reminder of the value of our metric in the original data.

```{r, cache=TRUE}
w <- wasserstein_bootstrapped(2000, gov_en[["span"]], gov_pcm[["span"]])
plot_metric_w_q(w, wasserstein_gov_obs, WessersteinMetric)

```


We can see that the results are generally between 0.75 and 0.95. This is very different from the results we got when permuting the language label, which would negate the null hypothesis (remember that we're looking for a combination of feature + metric which will be able to easily separate our two groups). According to both plots the combination of span_dep and the Wasserstein metric is able to do just that.

We now want to retrace our steps, this time using the span_gov measures instead, so as to see if one of these variables is a better predictor than the other.

```{r, cache=TRUE}
wasserstein_dep_obs <- transport::wasserstein1d(dep_en[["span"]], dep_pcm[["span"]])
wasserstein_dep_fake <- wasserstein_table(2000, dep, "english", "naija", "span")
print(plot_permuted_wasserstein(wasserstein_dep_fake, wasserstein_dep_obs))
w_2 <- wasserstein_bootstrapped(2000, dep_en[["span"]], dep_pcm[["span"]])
plot_metric_w_q(w_2, wasserstein_dep_obs, WessersteinMetric)
```


```{r}
print(wasserstein_dep_obs)
```

This second variable gives better results to distinguish both groups. In the original data we observe a value of  
We now have results based based on the Wasserstein distance. Next, we want to look at another distance which might be suited to this type of task, which is the Euclidean distance.

here is my attempt at computing the Euclidean distance for every pair of spans in span_dep seemed to failed because the table it created was too big. The first histogram shows distances in the same group, while the second one shows distances between different groups.

```{r}

gov_sample <- gov[sample(nrow(gov), 2000), ]
gov_sample$ID <- seq.int(nrow(gov_sample))
table_gov <- gov_sample %>% dplyr::select(language, span, ID) %>% dplyr::mutate(k=1)
table_gov_2 <- table_gov %>% dplyr::full_join(table_gov, by="k") %>% dplyr::filter(ID.x != ID.y) %>% dplyr::mutate(dist = sqrt((span.x - span.y)^2 + (span.x - span.y)^2))


same_group <- table_gov_2 %>% dplyr::filter(language.x == language.y) %>% dplyr::select(language.x, dist)
different_group <- table_gov_2 %>% dplyr::filter(language.x != language.y) %>% dplyr::select(language.x, dist)

plot_euclidean_distances <- function(data1) {
  ggplot2::ggplot(data1, ggplot2::aes(x=dist)) +
    ggplot2::geom_histogram(fill="#579ECF", colour="black", binwidth=0.01, bins=80)
}

print(plot_euclidean_distances(same_group))
print(plot_euclidean_distances(different_group))
```


